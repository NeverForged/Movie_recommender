{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA for Movie Recommeder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Jupyter notebook to cut down on time spent re-importig/loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark as ps\n",
    "from pyspark.sql.types import StructType, IntegerType, StringType, StructField, ArrayType\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id gender age occupation    zip\n",
      "975    976      M  35         14  89113\n",
      "976    977      M  25          2  80110\n",
      "977    978      M  18          0  19116\n",
      "978    979      M   1         10  48073\n",
      "979    980      M  25          6  92014\n",
      "980    981      M  25         20  02141\n",
      "981    982      F  25          9  92064\n",
      "982    983      F  25         16  99224\n",
      "983    984      M  50         16  92129\n",
      "984    985      M  25          4  32608\n",
      "985    986      F  56          0  19004\n",
      "986    987      F  35         17  48098\n",
      "987    988      M  50         11  48823\n",
      "988    989      M  50          0  20706\n",
      "989    990      M  18          6  10004\n",
      "990    991      F  25          9  48103\n",
      "991    992      F  35          3  02780\n",
      "992    993      M  25          0  45678\n",
      "993    994      M  18          2  92109\n",
      "994    995      F  18          4  96803\n",
      "995    996      M  25         17  98102\n",
      "996    997      M   1         19  15748\n",
      "997    998      M  45         20  10019\n",
      "998    999      M  25         15  62558\n",
      "999   1000      F  25          6  90027\n",
      "1000  1001      M  25          4  90210\n",
      "1001  1002      M  50         11  07043\n",
      "1002  1003      M  25          2  19320\n",
      "1003  1004      M  25          3  95136\n",
      "1004  1005      M  35         11  08003\n",
      "1005  1006      M  18          4  53220\n",
      "1006  1007      M  50         12  01960\n",
      "1007  1008      M  35          3  77064\n",
      "1008  1009      M  50          7  48315\n",
      "1009  1010      M  25          0  10310\n",
      "1010  1011      M  25          8  92115\n",
      "1011  1012      F  35          1  30004\n",
      "1012  1013      M  56         13  02576\n",
      "1013  1014      F  45         17  03054\n",
      "1014  1015      M  35          3  11220\n",
      "1015  1016      M  56         16  60044\n",
      "1016  1017      M  35          0  30906\n",
      "1017  1018      M  18          4  95616\n",
      "1018  1019      M  35          1  60640\n",
      "1019  1020      M  18         20  93455\n",
      "1020  1021      M  35          0  94559\n",
      "1021  1022      M  25          3  00918\n",
      "1022  1023      M  56         13  92675\n",
      "1023  1024      F  35          1  74135\n",
      "1024  1025      M  25         16  34677\n"
     ]
    }
   ],
   "source": [
    "# Start up some pyspark...\n",
    "spark = (ps.sql.SparkSession.builder\n",
    "             .master('local[4]')\n",
    "             .appName('Recommender')\n",
    "             .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Load Data\n",
    "users_rdd = sc.textFile('data/users.dat').map(lambda rowstr: rowstr.split('::'))\n",
    "# users_rdd.collect()\n",
    "\n",
    "schema = StructType([\n",
    "            StructField('id', StringType()),\n",
    "            StructField('gender', StringType()),\n",
    "            StructField('age', StringType()),\n",
    "            StructField('occupation', StringType()),\n",
    "            StructField('zip', StringType())])\n",
    "users_df = spark.createDataFrame(users_rdd, schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+----+\n",
      "|movie_id|               title|               genre|year|\n",
      "+--------+--------------------+--------------------+----+\n",
      "|       1|    Toy Story (1995)|[Animation, Child...|1995|\n",
      "|       2|      Jumanji (1995)|[Adventure, Child...|1995|\n",
      "|       3|Grumpier Old Men ...|   [Comedy, Romance]|1995|\n",
      "|       4|Waiting to Exhale...|     [Comedy, Drama]|1995|\n",
      "|       5|Father of the Bri...|            [Comedy]|1995|\n",
      "|       6|         Heat (1995)|[Action, Crime, T...|1995|\n",
      "|       7|      Sabrina (1995)|   [Comedy, Romance]|1995|\n",
      "|       8| Tom and Huck (1995)|[Adventure, Child...|1995|\n",
      "|       9| Sudden Death (1995)|            [Action]|1995|\n",
      "|      10|    GoldenEye (1995)|[Action, Adventur...|1995|\n",
      "|      11|American Presiden...|[Comedy, Drama, R...|1995|\n",
      "|      12|Dracula: Dead and...|    [Comedy, Horror]|1995|\n",
      "|      13|        Balto (1995)|[Animation, Child...|1995|\n",
      "|      14|        Nixon (1995)|             [Drama]|1995|\n",
      "|      15|Cutthroat Island ...|[Action, Adventur...|1995|\n",
      "|      16|       Casino (1995)|   [Drama, Thriller]|1995|\n",
      "|      17|Sense and Sensibi...|    [Drama, Romance]|1995|\n",
      "|      18|   Four Rooms (1995)|          [Thriller]|1995|\n",
      "|      19|Ace Ventura: When...|            [Comedy]|1995|\n",
      "|      20|  Money Train (1995)|            [Action]|1995|\n",
      "+--------+--------------------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_row(row):\n",
    "    '''\n",
    "    Seperate by '|' and make ino an array\n",
    "    '''\n",
    "    data = row.split('::')\n",
    "    # data[1] = data[1].split('(')[-1][:-1]\n",
    "    data[2] = data[2].split('|')\n",
    "    data.append(data[1].split('(')[-1][:-1])\n",
    "    return data\n",
    "\n",
    "movies_rdd = sc.textFile('data/movies.dat').map(parse_row)\n",
    "\n",
    "schema = StructType([\n",
    "            StructField('movie_id', StringType()),\n",
    "            StructField('title', StringType()),\n",
    "            StructField('genre', ArrayType(StringType())),\n",
    "            StructField('year', StringType())\n",
    "                    ])\n",
    "movies_df = spark.createDataFrame(movies_rdd, schema)\n",
    "movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+---------+\n",
      "|user|movie|rating|timestamp|\n",
      "+----+-----+------+---------+\n",
      "|6040|  858|     4|956703932|\n",
      "|6040|  593|     5|956703954|\n",
      "|6040| 2384|     4|956703954|\n",
      "|6040| 1961|     4|956703977|\n",
      "|6040| 2019|     5|956703977|\n",
      "|6040| 1419|     3|956704056|\n",
      "|6040|  573|     4|956704056|\n",
      "|6040| 3111|     5|956704056|\n",
      "|6040|  213|     5|956704056|\n",
      "|6040| 3505|     4|956704056|\n",
      "|6040| 1734|     2|956704081|\n",
      "|6040|  912|     5|956704191|\n",
      "|6040|  919|     5|956704191|\n",
      "|6040| 2503|     5|956704191|\n",
      "|6040|  527|     5|956704219|\n",
      "|6040|  318|     4|956704257|\n",
      "|6040| 1252|     5|956704257|\n",
      "|6040|  649|     5|956704257|\n",
      "|6040| 3289|     5|956704305|\n",
      "|6040|  759|     5|956704448|\n",
      "+----+-----+------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+------------------+-----------------+------------------+-------------------+\n",
      "|summary|              user|            movie|            rating|          timestamp|\n",
      "+-------+------------------+-----------------+------------------+-------------------+\n",
      "|  count|            800000|           800000|            800000|             800000|\n",
      "|   mean|      3403.0978375|    1849.25725625|        3.59047875|9.683921498700112E8|\n",
      "| stddev|1546.5890280451883|1086.852485159963|1.1203761265092087|      5820930.95649|\n",
      "|    min|               636|                1|                 1|          956703932|\n",
      "|    max|              6040|             3952|                 5|          975767289|\n",
      "+-------+------------------+-----------------+------------------+-------------------+\n",
      "\n",
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- movie: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = spark.read.csv('data/training.csv', header=True, sep=',', inferSchema=True)\n",
    "train_df.show()\n",
    "train_df.describe().show()\n",
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-55ce42c33dd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6040\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+----------+-----+\n",
      "| id|gender|age|occupation|  zip|\n",
      "+---+------+---+----------+-----+\n",
      "|  1|     F|  1|        10|48067|\n",
      "|  2|     M| 56|        16|70072|\n",
      "|  3|     M| 25|        15|55117|\n",
      "|  4|     M| 45|         7|02460|\n",
      "|  5|     M| 25|        20|55455|\n",
      "|  6|     F| 50|         9|55117|\n",
      "|  7|     M| 35|         1|06810|\n",
      "|  8|     M| 25|        12|11413|\n",
      "|  9|     M| 25|        17|61614|\n",
      "| 10|     F| 35|         1|95370|\n",
      "+---+------+---+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a join of data...\n",
    "users_df.createOrReplaceTempView('users')\n",
    "movies_df.createOrReplaceTempView('movies')\n",
    "train_df.createOrReplaceTempView('train')\n",
    "\n",
    "# SQL voodoo here...\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM users\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mu = train_df.agg(f.avg('rating')).take(1)[0]['avg(rating)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+---------+\n",
      "|user|movie|rating|timestamp|\n",
      "+----+-----+------+---------+\n",
      "|6036| 1280|     4|956711958|\n",
      "|6036|  235|     4|956712724|\n",
      "|6035|  440|     4|956712987|\n",
      "|6036| 2359|     2|956717201|\n",
      "|6037| 2353|     3|956718919|\n",
      "|6027| 2028|     5|956726454|\n",
      "|6026|  162|     5|956726748|\n",
      "|6025|  196|     3|956730882|\n",
      "|6036| 1722|     3|956753549|\n",
      "|6036|  241|     3|956753607|\n",
      "|6036| 1683|     3|956754004|\n",
      "|6036| 1748|     5|956754482|\n",
      "|6036| 1584|     4|956754614|\n",
      "|6021| 1073|     4|956757050|\n",
      "|6016| 3365|     3|956776862|\n",
      "|6016| 2993|     4|956777277|\n",
      "|6016|  494|     3|956777763|\n",
      "|6016| 2496|     3|956780812|\n",
      "|6006|  543|     1|956793406|\n",
      "|6002|  599|     4|956802789|\n",
      "+----+-----+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "        itemCol='movie',\n",
    "        userCol='user',\n",
    "        ratingCol='rating',\n",
    "        nonnegative=True,\n",
    "        regParam=0.1,\n",
    "        rank=10,\n",
    "        b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = als.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "| 10|[1.0157899, 0.090...|\n",
      "| 20|[0.52847815, 0.38...|\n",
      "| 30|[0.59129626, 0.54...|\n",
      "| 40|[0.4049925, 0.353...|\n",
      "| 50|[1.2174305, 0.447...|\n",
      "| 60|[0.33509123, 0.50...|\n",
      "| 70|[0.831674, 0.0265...|\n",
      "| 80|[0.54933816, 0.42...|\n",
      "| 90|[0.5714423, 0.253...|\n",
      "|100|[0.56420135, 0.20...|\n",
      "|110|[1.4001731, 0.425...|\n",
      "|120|[0.7430254, 0.410...|\n",
      "|130|[0.33988208, 0.06...|\n",
      "|140|[0.33167064, 0.50...|\n",
      "|150|[0.98682827, 0.39...|\n",
      "|160|[0.31674203, 0.17...|\n",
      "|170|[0.64632416, 0.21...|\n",
      "|180|[1.2231518, 0.333...|\n",
      "|190|[0.3439357, 0.351...|\n",
      "|200|[0.0, 0.68877727,...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommender.itemFactors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+---------+----------+\n",
      "|user|movie|rating|timestamp|prediction|\n",
      "+----+-----+------+---------+----------+\n",
      "| 673|  148|     5|975620824| 3.6031673|\n",
      "|4227|  148|     2|965659724|  1.909593|\n",
      "|3184|  148|     4|968708953| 3.2237186|\n",
      "|4784|  148|     3|970000570| 2.9678636|\n",
      "|2383|  148|     2|974417654|  2.389425|\n",
      "|1242|  148|     3|974909976| 2.9519734|\n",
      "|3539|  148|     3|966932408| 2.7693977|\n",
      "|1069|  148|     2|974945135|  2.535724|\n",
      "|1605|  148|     2|974930221| 2.2200673|\n",
      "|1150|  148|     2|974875106| 2.4321134|\n",
      "|3829|  148|     2|965940170| 2.2759461|\n",
      "|2456|  148|     2|974178993| 2.4392943|\n",
      "|2507|  148|     4|974082717|  3.146665|\n",
      "|3053|  148|     3|970170090| 2.6374075|\n",
      "|3841|  463|     3|966003085| 2.6202276|\n",
      "|3650|  463|     2|966459084| 2.5214236|\n",
      "|3151|  463|     5|968916009| 3.9031835|\n",
      "|4858|  463|     3|963746396| 2.4411056|\n",
      "|2629|  463|     4|973625620| 3.0589423|\n",
      "|3328|  463|     4|967918151| 3.1816363|\n",
      "+----+-----+------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommender.transform(train_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+-------------------+\n",
      "|summary|              user|            movie|            rating|          timestamp|\n",
      "+-------+------------------+-----------------+------------------+-------------------+\n",
      "|  count|            800000|           800000|            800000|             800000|\n",
      "|   mean|      3403.0978375|    1849.25725625|        3.59047875|9.683921498700112E8|\n",
      "| stddev|1546.5890280451883|1086.852485159963|1.1203761265092087|      5820930.95649|\n",
      "|    min|               636|                1|                 1|          956703932|\n",
      "|    max|              6040|             3952|                 5|          975767289|\n",
      "+-------+------------------+-----------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
